#!/usr/bin/env python3
"""
æ¯æ—¥æ•°æ®æ‹‰å–è„šæœ¬

ç”¨é€”ï¼š
- æ¯å¤©æ—©ç›˜å‰è¿è¡Œä¸€æ¬¡ï¼ˆ8:00-8:30ï¼‰
- æ‰¹é‡æ‹‰å–å½“æ—¥æ‰€æœ‰éœ€è¦çš„æ•°æ®
- ç¼“å­˜åˆ°æœ¬åœ°æ–‡ä»¶ï¼Œä¾›åç»­å¿«é€Ÿè¯»å–
- é¿å…é¢‘ç‡é™åˆ¶å’Œé‡å¤æŸ¥è¯¢

ä½¿ç”¨æ–¹å¼ï¼š
    python scripts/fetch_daily_data.py

è¯´æ˜ï¼š
- Tushareæœ‰IPé™åˆ¶ï¼ˆæ¯ä¸ªtokenæœ€å¤š2ä¸ªIPï¼‰ï¼Œå¦‚æœé‡åˆ°IPé™åˆ¶ï¼š
  æ–¹æ³•1ï¼šåœ¨åŒä¸€å°æœºå™¨ä¸Šè¿è¡Œï¼ˆæ¨èï¼‰
  æ–¹æ³•2ï¼šåªæ‹‰å–akshareæ•°æ®ï¼Œæ¦‚å¿µæ•°æ®é€šè¿‡å®æ—¶APIè·å–ï¼ˆé™çº§æ¨¡å¼ï¼‰
"""

import sys
import os
import json
import time
from datetime import datetime

# æ·»åŠ æ¨¡å—è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)

import akshare as ak

# å°è¯•å¯¼å…¥Tushareï¼ˆå¯èƒ½å¤±è´¥ï¼‰
TUSHARE_AVAILABLE = False
try:
    import tushare as ts
    from modules.config import TUSHARE_TOKEN
    ts.set_token(TUSHARE_TOKEN)
    pro = ts.pro_api()
    TUSHARE_AVAILABLE = True
except Exception as e:
    print(f"âš ï¸  Tushareä¸å¯ç”¨ï¼š{e}")
    print("å°†ä½¿ç”¨é™çº§æ¨¡å¼ï¼ˆåªæ‹‰å–akshareæ•°æ®ï¼‰")


def fetch_today_data():
    """æ‹‰å–ä»Šæ—¥æ‰€æœ‰æ•°æ®"""
    today = datetime.now().strftime("%Y%m%d")
    data_dir = os.path.join(parent_dir, "data", today)
    os.makedirs(data_dir, exist_ok=True)
    
    print("="*60)
    print(f"ğŸ“… å¼€å§‹æ‹‰å– {today} æ•°æ®")
    print("="*60)
    
    # 1. æ¶¨åœè‚¡ç¥¨
    print("\nã€1/5ã€‘è·å–æ¶¨åœè‚¡ç¥¨...")
    try:
        df = ak.stock_zt_pool_em(date=today)
        if df is not None and not df.empty:
            # æ ¼å¼åŒ–JSONå†™å…¥
            data = json.loads(df.to_json(orient='records', force_ascii=False))
            with open(os.path.join(data_dir, "limit_up_stocks.json"), 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            print(f"âœ… æ¶¨åœè‚¡ç¥¨ï¼š{len(df)} åª")
            limit_up_count = len(df)
        else:
            print("âš ï¸  ä»Šæ—¥æš‚æ— æ¶¨åœ")
            limit_up_count = 0
    except Exception as e:
        print(f"âŒ å¤±è´¥ï¼š{e}")
        limit_up_count = 0
    
    # 2. è¿æ¿æ•°æ®
    print("\nã€2/5ã€‘è·å–è¿æ¿æ•°æ®...")
    try:
        df = ak.stock_zt_pool_strong_em(date=today)
        if df is not None and not df.empty:
            # æ ¼å¼åŒ–JSONå†™å…¥
            data = json.loads(df.to_json(orient='records', force_ascii=False))
            with open(os.path.join(data_dir, "continuous_limit_up.json"), 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            print(f"âœ… è¿æ¿è‚¡ç¥¨ï¼š{len(df)} åª")
        else:
            print("âš ï¸  ä»Šæ—¥æš‚æ— è¿æ¿")
    except Exception as e:
        print(f"âŒ å¤±è´¥ï¼š{e}")
    
    # 3. ä¸œæ–¹è´¢å¯Œäººæ°”æ¦œ
    print("\nã€3/5ã€‘è·å–ä¸œæ–¹è´¢å¯Œäººæ°”æ¦œ...")
    try:
        df = ak.stock_hot_rank_em()
        if df is not None and not df.empty:
            # æ ¼å¼åŒ–JSONå†™å…¥
            data = json.loads(df.to_json(orient='records', force_ascii=False))
            with open(os.path.join(data_dir, "em_hot_rank.json"), 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            print(f"âœ… äººæ°”æ¦œï¼š{len(df)} åª")
        else:
            print("âš ï¸  äººæ°”æ¦œä¸ºç©º")
    except Exception as e:
        print(f"âŒ å¤±è´¥ï¼š{e}")
    
    # 4. é¾™è™æ¦œï¼ˆå¯é€‰ï¼Œç»å¸¸å¤±è´¥ï¼‰
    print("\nã€4/5ã€‘è·å–é¾™è™æ¦œ...")
    yesterday = datetime.now().strftime("%Y%m%d")
    try:
        df = ak.stock_lhb_detail_em(start_date=yesterday, end_date=yesterday)
        if df is not None and not df.empty:
            # æ ¼å¼åŒ–JSONå†™å…¥
            data = json.loads(df.to_json(orient='records', force_ascii=False))
            with open(os.path.join(data_dir, "dragon_tiger_list.json"), 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            print(f"âœ… é¾™è™æ¦œï¼š{len(df)} åª")
        else:
            print("âš ï¸  é¾™è™æ¦œä¸ºç©º")
    except Exception as e:
        print(f"âš ï¸  é¾™è™æ¦œè·å–å¤±è´¥ï¼ˆè¿™ä¸ªæ¥å£ä¸ç¨³å®šï¼‰ï¼š{e}")
    
    # 5. æ‰¹é‡è·å–æ¶¨åœè‚¡ç¥¨çš„æ¦‚å¿µ
    print("\nã€5/5ã€‘æ‰¹é‡è·å–è‚¡ç¥¨æ¦‚å¿µ...")
    
    # è¯»å–æ¶¨åœè‚¡ç¥¨åˆ—è¡¨
    limit_up_path = os.path.join(data_dir, "limit_up_stocks.json")
    if not os.path.exists(limit_up_path) or limit_up_count == 0:
        print("âš ï¸  æœªæ‰¾åˆ°æ¶¨åœè‚¡ç¥¨æ•°æ®ï¼Œè·³è¿‡æ¦‚å¿µæŸ¥è¯¢")
        return
    
    with open(limit_up_path, 'r', encoding='utf-8') as f:
        limit_up_stocks = json.load(f)
    
    stock_concepts = {}
    total = len(limit_up_stocks)
    
    print(f"éœ€è¦æŸ¥è¯¢ {total} åªè‚¡ç¥¨çš„æ¦‚å¿µ...")
    
    # æ–¹æ¡ˆAï¼šä¼˜å…ˆä½¿ç”¨ akshare çš„è¡Œä¸šæ•°æ®ï¼ˆå…è´¹ã€ç¨³å®šï¼‰
    print("ä½¿ç”¨ akshare çš„è¡Œä¸šæ•°æ®ï¼ˆå…è´¹ã€æ— é™åˆ¶ï¼‰")
    for i, stock in enumerate(limit_up_stocks, 1):
        code = str(stock['ä»£ç ']).zfill(6)
        name = stock['åç§°']
        industry = stock.get('æ‰€å±è¡Œä¸š', '')
        
        # ä½¿ç”¨è¡Œä¸šä½œä¸ºæ¦‚å¿µï¼ˆç®€åŒ–ç‰ˆï¼‰
        concepts = [industry] if industry else []
        
        stock_concepts[code] = {
            'åç§°': name,
            'æ¦‚å¿µ': concepts,
            'è¡Œä¸š': industry
        }
        print(f"  [{i}/{total}] {name} ({code}): {industry}")
    
    # æ–¹æ¡ˆBï¼šå¦‚æœ Tushare å¯ç”¨ä¸”æ—  IP é™åˆ¶ï¼Œå°è¯•è¡¥å……è¯¦ç»†æ¦‚å¿µï¼ˆå¯é€‰ï¼‰
    if TUSHARE_AVAILABLE:
        print("\nå°è¯•ä½¿ç”¨ Tushare è¡¥å……è¯¦ç»†æ¦‚å¿µï¼ˆå¯èƒ½é‡åˆ° IP é™åˆ¶ï¼‰...")
        success_count = 0
        failed_count = 0
        
        for i, stock in enumerate(limit_up_stocks, 1):
            code = str(stock['ä»£ç ']).zfill(6)
            name = stock['åç§°']
            
            # è½¬æ¢ä¸ºTushareä»£ç 
            if code.startswith('6'):
                ts_code = f"{code}.SH"
            elif code.startswith('0') or code.startswith('3'):
                ts_code = f"{code}.SZ"
            elif code.startswith('8') or code.startswith('4'):
                ts_code = f"{code}.BJ"
            else:
                continue
            
            try:
                # æŸ¥è¯¢æ¦‚å¿µ
                time.sleep(0.5)
                df = pro.concept_detail(ts_code=ts_code, fields='id,concept_name')
                
                if df is not None and not df.empty:
                    concepts = df['concept_name'].tolist()
                    # åˆå¹¶è¡Œä¸šå’Œæ¦‚å¿µ
                    industry = stock_concepts[code].get('è¡Œä¸š', '')
                    all_concepts = [industry] + concepts if industry else concepts
                    stock_concepts[code]['æ¦‚å¿µ'] = list(set(all_concepts))  # å»é‡
                    print(f"  [{i}/{total}] {name}: è¡¥å…… {len(concepts)} ä¸ªæ¦‚å¿µ")
                    success_count += 1
                    
            except Exception as e:
                error_msg = str(e)
                failed_count += 1
                
                # å¦‚æœæ˜¯IPé™åˆ¶ï¼Œæå‰é€€å‡º
                if 'IP' in error_msg or 'ip' in error_msg.lower():
                    print(f"\nâš ï¸  Tushare IPé™åˆ¶ï¼š{e}")
                    print(f"å·²è¡¥å…… {success_count}/{total} åªè‚¡ç¥¨çš„è¯¦ç»†æ¦‚å¿µ")
                    print("å…¶ä½™è‚¡ç¥¨ä½¿ç”¨è¡Œä¸šæ•°æ®ï¼ˆå·²è¶³å¤ŸåŒ¹é…é€»è¾‘åº“ï¼‰")
                    break
        
        if success_count > 0:
            print(f"\nâœ… Tushare è¡¥å……å®Œæˆï¼š{success_count}/{total} åªè‚¡ç¥¨")
    else:
        print("\nğŸ’¡ Tushare ä¸å¯ç”¨ï¼Œä½¿ç”¨è¡Œä¸šæ•°æ®ï¼ˆå·²è¶³å¤ŸåŒ¹é…é€»è¾‘åº“ï¼‰")
    
    # ä¿å­˜æ¦‚å¿µæ•°æ®åˆ°æ–‡ä»¶
    with open(os.path.join(data_dir, "stock_concepts.json"), 'w', encoding='utf-8') as f:
        json.dump(stock_concepts, f, ensure_ascii=False, indent=2)
    print(f"\nâœ… æ¦‚å¿µæ•°æ®å·²ä¿å­˜ï¼š{len(stock_concepts)} åªè‚¡ç¥¨")
    
    # åˆ›å»ºè½¯é“¾æ¥åˆ°latest
    latest_link = os.path.join(parent_dir, "data", "latest")
    if os.path.exists(latest_link) or os.path.islink(latest_link):
        os.remove(latest_link)
    os.symlink(today, latest_link)
    
    print("\n" + "="*60)
    print(f"ğŸ‰ æ•°æ®æ‹‰å–å®Œæˆï¼ä¿å­˜åœ¨: data/{today}/")
    print("="*60)
    print("\næç¤ºï¼šç°åœ¨å¯ä»¥ä½¿ç”¨ /longtou-strategy ç­›é€‰ï¼Œé€Ÿåº¦ä¼šæ›´å¿«ï¼")


if __name__ == "__main__":
    fetch_today_data()

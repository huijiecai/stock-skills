#!/usr/bin/env python3
"""
å†å²å›æµ‹è„šæœ¬

ç”¨é€”ï¼š
- è·å–æœ€è¿‘Nå¤©çš„æ¶¨åœæ¿æ•°æ®
- è¿½è¸ªæ¯åªè‚¡ç¥¨çš„åç»­è¡¨ç°
- åˆ†æèµšé’±æ¨¡å¼å’Œäºé’±æ¨¡å¼
- ç”Ÿæˆç­–ç•¥ä¼˜åŒ–å»ºè®®

ä½¿ç”¨æ–¹å¼ï¼š
    python scripts/run_backtest.py --days 30 --sample 100
"""

import sys
import os
import argparse
import json
from datetime import datetime

# æ·»åŠ æ¨¡å—è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)

from modules import BacktestEngine, PatternAnalyzer


def run_backtest(days: int = 30, sample_size: int = 100):
    """
    è¿è¡Œå›æµ‹åˆ†æ
    
    Args:
        days: å›æµ‹å¤©æ•°
        sample_size: é‡‡æ ·æ•°é‡
    """
    print("="*60)
    print(f"ğŸš€ é¾™å¤´æˆ˜æ³•å†å²å›æµ‹")
    print("="*60)
    print(f"å›æµ‹å‘¨æœŸï¼šæœ€è¿‘ {days} ä¸ªäº¤æ˜“æ—¥")
    print(f"é‡‡æ ·æ•°é‡ï¼š{sample_size} åªè‚¡ç¥¨")
    print("="*60)
    
    # 1. åˆå§‹åŒ–å›æµ‹å¼•æ“
    engine = BacktestEngine(days=days)
    
    # 2. è·å–äº¤æ˜“æ—¥
    trading_days = engine.get_trading_days(days)
    
    # 3. è·å–æ¶¨åœè‚¡ç¥¨æ•°æ®
    limit_up_data = engine.get_limit_up_stocks_batch(trading_days)
    
    if not limit_up_data:
        print("\nâŒ æœªèƒ½è·å–åˆ°æ¶¨åœæ•°æ®ï¼Œé€€å‡º")
        return
    
    # ç»Ÿè®¡æ¶¨åœè‚¡ç¥¨æ€»æ•°
    total_stocks = sum(len(df) for df in limit_up_data.values())
    print(f"\nğŸ“Š æ¶¨åœè‚¡ç¥¨æ€»æ•°ï¼š{total_stocks} åª")
    
    # 4. è®¡ç®—ç»­æ¿ç‡å’Œåç»­è¡¨ç°
    backtest_df = engine.calculate_continuation_rate(limit_up_data, sample_size=sample_size)
    
    if backtest_df.empty:
        print("\nâŒ å›æµ‹æ•°æ®ä¸ºç©ºï¼Œé€€å‡º")
        return
    
    # 5. ä¿å­˜åŸå§‹æ•°æ®
    data_dir = os.path.join(parent_dir, "data", "backtest")
    os.makedirs(data_dir, exist_ok=True)
    
    today_str = datetime.now().strftime("%Y%m%d")
    csv_path = os.path.join(data_dir, f"backtest_{today_str}_days{days}.csv")
    backtest_df.to_csv(csv_path, index=False, encoding='utf-8-sig')
    print(f"\nğŸ’¾ åŸå§‹æ•°æ®å·²ä¿å­˜ï¼š{csv_path}")
    
    # 6. æ¨¡å¼åˆ†æ
    print("\n" + "="*60)
    print("ğŸ“Š æ¨¡å¼åˆ†æ")
    print("="*60)
    
    analyzer = PatternAnalyzer(backtest_df)
    
    # æ—¶é—´æ¨¡å¼
    time_pattern = analyzer.analyze_time_pattern()
    print("\n### æ—¶é—´æ¨¡å¼åˆ†æ")
    for category, info in time_pattern.items():
        if info['æ•°é‡'] > 0:
            print(f"\n**{category}** ({info['å®šä¹‰']})")
            print(f"  æ ·æœ¬æ•°ï¼š{info['æ•°é‡']}")
            print(f"  T+1å¹³å‡æ”¶ç›Šï¼š{info['T+1å¹³å‡æ”¶ç›Š']}")
            print(f"  T+1èƒœç‡ï¼š{info['T+1èƒœç‡']}")
            print(f"  T+3å¹³å‡æ”¶ç›Šï¼š{info['T+3å¹³å‡æ”¶ç›Š']}")
    
    # è¡Œä¸šæ¨¡å¼
    industry_pattern = analyzer.analyze_industry_pattern()
    print("\n### è¡Œä¸šæ¨¡å¼åˆ†æï¼ˆTOP10ï¼‰")
    for i, ind in enumerate(industry_pattern[:10], 1):
        print(f"{i}. {ind['è¡Œä¸š']}ï¼š")
        print(f"   æ ·æœ¬æ•°={ind['æ ·æœ¬æ•°']}, "
              f"T+1æ”¶ç›Š={ind['T+1å¹³å‡æ”¶ç›Š']:.2%}, "
              f"èƒœç‡={ind['T+1èƒœç‡']:.1%}")
    
    # èµšé’±æ¨¡å¼
    winning_patterns = analyzer.find_winning_patterns(top_n=5)
    print("\n### ğŸ”¥ èµšé’±æ¨¡å¼TOP5")
    for i, pattern in enumerate(winning_patterns, 1):
        print(f"\n{i}. **{pattern['æ¨¡å¼']}**")
        print(f"   ç‰¹å¾ï¼š{pattern['ç‰¹å¾']}")
        print(f"   æ ·æœ¬æ•°ï¼š{pattern['æ ·æœ¬æ•°']}")
        print(f"   T+1å¹³å‡æ”¶ç›Šï¼š{pattern['T+1å¹³å‡æ”¶ç›Š']:.2%}")
        print(f"   T+1èƒœç‡ï¼š{pattern['T+1èƒœç‡']:.1%}")
        print(f"   T+3å¹³å‡æ”¶ç›Šï¼š{pattern['T+3å¹³å‡æ”¶ç›Š']:.2%}")
    
    # äºé’±æ¨¡å¼
    losing_patterns = analyzer.find_losing_patterns(top_n=3)
    print("\n### âš ï¸  äºé’±æ¨¡å¼ï¼ˆéœ€è¦é¿å…ï¼‰")
    for i, pattern in enumerate(losing_patterns, 1):
        print(f"\n{i}. **{pattern['æ¨¡å¼']}**")
        print(f"   ç‰¹å¾ï¼š{pattern['ç‰¹å¾']}")
        print(f"   æ ·æœ¬æ•°ï¼š{pattern['æ ·æœ¬æ•°']}")
        print(f"   T+1å¹³å‡æ”¶ç›Šï¼š{pattern['T+1å¹³å‡æ”¶ç›Š']:.2%}")
        print(f"   T+1èƒœç‡ï¼š{pattern['T+1èƒœç‡']:.1%}")
        if 'é£é™©' in pattern:
            print(f"   âš ï¸ {pattern['é£é™©']}")
    
    # ä¼˜åŒ–å»ºè®®
    suggestions = analyzer.generate_suggestions()
    print("\n### ğŸ’¡ ç­–ç•¥ä¼˜åŒ–å»ºè®®")
    for suggestion in suggestions:
        print(f"  {suggestion}")
    
    # 7. ä¿å­˜åˆ†ææŠ¥å‘Š
    report = {
        'å›æµ‹å‘¨æœŸ': f"{days}ä¸ªäº¤æ˜“æ—¥",
        'é‡‡æ ·æ•°é‡': sample_size,
        'åˆ†æè‚¡ç¥¨': len(backtest_df),
        'æ—¶é—´æ¨¡å¼': {k: {
            'æ•°é‡': v['æ•°é‡'],
            'T+1å¹³å‡æ”¶ç›Š': v['T+1å¹³å‡æ”¶ç›Š'],
            'T+1èƒœç‡': v['T+1èƒœç‡']
        } for k, v in time_pattern.items() if v['æ•°é‡'] > 0},
        'èµšé’±æ¨¡å¼': winning_patterns,
        'äºé’±æ¨¡å¼': losing_patterns,
        'ä¼˜åŒ–å»ºè®®': suggestions
    }
    
    report_path = os.path.join(data_dir, f"report_{today_str}_days{days}.json")
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ åˆ†ææŠ¥å‘Šå·²ä¿å­˜ï¼š{report_path}")
    
    print("\n" + "="*60)
    print("âœ… å›æµ‹å®Œæˆï¼")
    print("="*60)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='é¾™å¤´æˆ˜æ³•å†å²å›æµ‹')
    parser.add_argument('--days', type=int, default=30, help='å›æµ‹å¤©æ•°ï¼ˆé»˜è®¤30å¤©ï¼‰')
    parser.add_argument('--sample', type=int, default=100, help='é‡‡æ ·æ•°é‡ï¼ˆé»˜è®¤100åªï¼‰')
    
    args = parser.parse_args()
    
    run_backtest(days=args.days, sample_size=args.sample)

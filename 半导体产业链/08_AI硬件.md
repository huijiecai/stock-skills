# 08 AI硬件

> AI的"发动机"，算力时代的核心资产

---

## 一、AI为什么需要专用硬件？

### 通俗理解

> **AI计算 = 大规模矩阵运算**
>
> 传统CPU是"通才"，AI芯片是"专才"，专门干矩阵乘法这件事。

### CPU vs GPU vs AI芯片

```
┌─────────────────────────────────────────────────────────────┐
│                计算架构对比                                  │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  CPU（通用处理器）          GPU（图形处理器）               │
│  ┌─────────────────┐       ┌─────────────────────────────┐ │
│  │ ████  ████      │       │ ▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪ │ │
│  │ 控制  缓存      │       │ ▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪ │ │
│  │ ┌──┬──┬──┬──┐   │       │ ▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪ │ │
│  │ │核│核│核│核│   │       │ ▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪ │ │
│  │ └──┴──┴──┴──┘   │       └─────────────────────────────┘ │
│  └─────────────────┘                                        │
│                                                             │
│  • 4-64个大核                • 数千个小核                   │
│  • 擅长复杂逻辑              • 擅长并行计算                  │
│  • 串行能力强                • 矩阵运算能力强                │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 为什么GPU适合AI？

| 特性 | CPU | GPU | 对AI的意义 |
|------|-----|-----|------------|
| 核心数 | 4-64 | 数千-上万 | AI需要并行计算 |
| 内存带宽 | ~50GB/s | ~1TB/s(HBM) | AI需要喂数据 |
| 浮点算力 | 低 | 极高 | AI需要大量乘加 |
| 能效比 | 低 | 高 | AI计算量大 |

---

## 二、AI芯片分类

### 按类型分

| 类型 | 说明 | 代表 | 优势 | 劣势 |
|------|------|------|------|------|
| **GPU** | 通用图形处理器 | 英伟达H100 | 生态完善 | 功耗高 |
| **ASIC** | 专用AI芯片 | 谷歌TPU | 效率最高 | 通用性差 |
| **FPGA** | 可编程芯片 | 赛灵思 | 灵活 | 性能有限 |

### 按应用场景分

| 场景 | 需求 | 代表芯片 |
|------|------|----------|
| **云端训练** | 最高算力 | 英伟达H100/H200/B100 |
| **云端推理** | 高吞吐量 | 英伟达L40、AMD MI300 |
| **边缘推理** | 低功耗 | 英伟达Jetson、寒武纪 |
| **端侧AI** | 超低功耗 | NPU、DSP |

---

## 三、英伟达的统治地位

### 市场份额

```
AI训练芯片市场份额（2025年）：

英伟达:      ████████████████████████████████████████████ 85%+
AMD:         ████ 8%
谷歌TPU:     ██ 4%
其他:        █ 3%

⚠️ 英伟达在AI芯片领域是绝对霸主！
```

### 英伟达产品演进

| 产品 | 发布年 | 工艺 | HBM | 算力(FP8) |
|------|--------|------|-----|-----------|
| V100 | 2017 | 12nm | HBM2 16GB | 125 TFLOPS |
| A100 | 2020 | 7nm | HBM2e 80GB | 312 TFLOPS |
| **H100** | 2022 | 4nm | HBM3 80GB | 1979 TFLOPS |
| **H200** | 2023 | 4nm | HBM3e 141GB | 1979 TFLOPS |
| **B100** | 2024 | 4nm | HBM3e 192GB | 更高 |
| **B200** | 2025 | 3nm | HBM3e | 更高 |

### 英伟达的护城河

| 护城河 | 说明 |
|--------|------|
| **CUDA生态** | 90%+的AI框架基于CUDA |
| **软件栈** | cuDNN、TensorRT等完善 |
| **先发优势** | 积累了10年+ |
| **客户绑定** | 迁移成本极高 |
| **硬件领先** | 性能持续领先 |

---

## 四、主要AI芯片玩家

### 国际巨头

| 公司 | 产品 | 定位 | 客户 |
|------|------|------|------|
| **英伟达** | H100/H200/B100 | 训练+推理霸主 | 全球云厂商 |
| **AMD** | MI300X/MI325 | 追赶者 | 微软、Meta |
| **Intel** | Gaudi 3 | 追赶者 | 部分云厂商 |
| **谷歌** | TPU v5 | 自用ASIC | 谷歌云 |
| **亚马逊** | Trainium 2 | 自用ASIC | AWS |
| **微软** | Maia | 自用ASIC | Azure |

### 中国AI芯片

| 公司 | 产品 | 对标 | 现状 |
|------|------|------|------|
| **华为** | 昇腾910B/C | H100 | 国内最强，自主生态 |
| **寒武纪** | 思元590 | A100 | 上市公司 |
| **海光** | DCU | AMD MI | 出货增长 |
| **摩尔线程** | MTT S4000 | 消费级GPU | 游戏+AI |
| **壁仞科技** | BR100 | H100 | 受制裁 |
| **燧原科技** | 邃思 | A100 | 推理为主 |
| **天数智芯** | BI150 | A100 | 追赶中 |

### 华为昇腾详解

```
华为AI芯片布局：

┌─────────────────────────────────────────────────────────────┐
│                    华为昇腾体系                              │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  【芯片】          【系统】           【软件】               │
│  昇腾910B/C       Atlas 800/900      MindSpore             │
│  (AI处理器)       (AI服务器)         (AI框架)              │
│                                                             │
│  优势：                                                      │
│  • 国产自主可控                                              │
│  • 有自己的软件生态（MindSpore）                             │
│  • 与华为云深度绑定                                          │
│                                                             │
│  劣势：                                                      │
│  • 性能与H100有差距                                          │
│  • 生态不如CUDA成熟                                          │
│  • 产能受设备限制                                            │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

---

## 五、AI服务器

### AI服务器与普通服务器的区别

| 对比项 | 普通服务器 | AI服务器 |
|--------|------------|----------|
| 核心部件 | CPU | GPU/AI芯片 |
| 功耗 | ~500W | 3000W~10000W+ |
| 价格 | 几万~几十万 | 几十万~几百万 |
| 散热 | 风冷为主 | 液冷为主 |
| 互连 | 普通网络 | NVLink/IB |

### AI服务器产业链

```
┌─────────────────────────────────────────────────────────────┐
│                  AI服务器产业链                              │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  【核心芯片】       【存储】          【网络】               │
│  英伟达GPU         HBM              InfiniBand             │
│  华为昇腾          DDR5             以太网                  │
│                    SSD                                      │
│       ↓               ↓                 ↓                   │
│  ┌─────────────────────────────────────────────────┐       │
│  │              AI服务器整机                        │       │
│  │  浪潮、新华三、联想、超聚变、宁畅等              │       │
│  └─────────────────────────────────────────────────┘       │
│       ↓                                                     │
│  【散热】          【电源】          【机柜】               │
│  液冷系统          大功率电源        服务器机柜             │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 中国AI服务器厂商

| 公司 | 市场地位 | 主要客户 |
|------|----------|----------|
| **浪潮信息** | 国内龙头 | 互联网、运营商 |
| **新华三** | 第二梯队 | 政企、运营商 |
| **联想** | 第二梯队 | 全球市场 |
| **超聚变** | 原华为x86 | 政企 |
| **宁畅** | 新锐 | 互联网 |

---

## 六、AI芯片的瓶颈

### 当前瓶颈

```
AI芯片供需情况（2025年）：

需求：████████████████████████████████████████ 100%
供给：██████████████████████████ 60%

主要瓶颈：
1. CoWoS先进封装产能
2. HBM产能
3. 台积电代工产能
```

### 为什么缺货？

| 瓶颈 | 原因 |
|------|------|
| **CoWoS封装** | 台积电产能有限，扩产需要时间 |
| **HBM存储** | SK海力士产能被英伟达锁定 |
| **先进制程** | 4nm/3nm产能紧张 |

---

## 七、A股核心标的

### AI芯片

| 公司 | 代码 | 主营 | 看点 |
|------|------|------|------|
| **寒武纪** | 688256 | AI芯片 | 国产AI芯片龙头 |
| **海光信息** | 688041 | CPU/DCU | x86+AI芯片 |
| **景嘉微** | 300474 | GPU | 军用GPU |

### AI服务器

| 公司 | 代码 | 主营 | 看点 |
|------|------|------|------|
| **浪潮信息** | 000977 | AI服务器 | 国内服务器龙头 |
| **工业富联** | 601138 | AI服务器 | 英伟达供应链 |

### AI散热/电源

| 公司 | 代码 | 主营 | 看点 |
|------|------|------|------|
| **英维克** | 002837 | 液冷散热 | 数据中心温控 |
| **高澜股份** | 300499 | 液冷 | 液冷龙头 |
| **中兴通讯** | 000063 | 液冷/服务器 | 综合ICT |

---

## 八、投资逻辑

### 核心逻辑

```
1. AI算力需求爆发
   • 大模型训练需要海量算力
   • AI应用落地需要推理算力
   • 利好：英伟达供应链

2. 国产替代
   • 美国限制AI芯片出口
   • 国内被迫采购华为/寒武纪
   • 利好：寒武纪、海光

3. 产业链受益
   • AI芯片带动存储（HBM）
   • AI芯片带动封装（CoWoS）
   • AI芯片带动服务器整机
```

### 风险提示

| 风险 | 说明 |
|------|------|
| ⚠️ 估值高 | AI概念估值普遍较高 |
| ⚠️ 技术差距 | 国产与英伟达差距大 |
| ⚠️ 政策风险 | 制裁可能加剧 |
| ⚠️ 竞争加剧 | 国产芯片相互竞争 |

---

[上一篇：存储芯片](./07_存储芯片.md) | [返回目录](./README.md) | [下一篇：PCB与基板](./09_PCB与基板.md)

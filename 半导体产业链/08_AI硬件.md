# 08 AI硬件

> AI的"发动机"，算力时代的核心资产

---

## 一、AI芯片总览

### 1️⃣ 是什么？

> **AI芯片 = 专门做AI计算的芯片**
>
> 传统CPU是"通才"，AI芯片是"专才"，专门干矩阵乘法这件事。

```
┌─────────────────────────────────────────────────────────────┐
│                计算架构对比                                  │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  CPU（通用处理器）          GPU（图形处理器）               │
│  ┌─────────────────┐       ┌─────────────────────────────┐ │
│  │ ████  ████      │       │ ▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪ │ │
│  │ 控制  缓存      │       │ ▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪ │ │
│  │ ┌──┬──┬──┬──┐   │       │ ▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪ │ │
│  │ │核│核│核│核│   │       │ ▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪▪ │ │
│  │ └──┴──┴──┴──┘   │       └─────────────────────────────┘ │
│  └─────────────────┘                                        │
│                                                             │
│  • 4-64个大核                • 数千个小核                   │
│  • 擅长复杂逻辑              • 擅长并行计算                  │
│  • 串行能力强                • 矩阵运算能力强                │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 2️⃣ 市场规模

```
AI芯片市场规模（2025年）：

市场规模：约 600亿美元
年增速：约 40-50%（增速最快的芯片领域）

按场景分：
云端训练:   ████████████████████████████████████████ 50%
云端推理:   ████████████████████████████████ 40%
边缘推理:   ████████ 10%
```

### 3️⃣ AI芯片分类

| 类型 | 说明 | 代表 | 优势 | 劣势 |
|------|------|------|------|------|
| **GPU** | 通用图形处理器 | 英伟达H100 | 生态完善 | 功耗高 |
| **ASIC** | 专用AI芯片 | 谷歌TPU | 效率最高 | 通用性差 |
| **FPGA** | 可编程芯片 | 赛灵思 | 灵活 | 性能有限 |

| 场景 | 需求 | 代表芯片 |
|------|------|----------|
| **云端训练** | 最高算力 | 英伟达H100/H200/B100 |
| **云端推理** | 高吞吐量 | 英伟达L40、AMD MI300 |
| **边缘推理** | 低功耗 | 英伟达Jetson、寒武纪 |
| **端侧AI** | 超低功耗 | NPU、DSP |

---

## 二、英伟达的统治地位

### 1️⃣ 市场份额

```
AI训练芯片市场份额（2025年）：

英伟达:      ████████████████████████████████████████████ 85%+
AMD:         ████ 8%
谷歌TPU:     ██ 4%
其他:        █ 3%

⚠️ 英伟达在AI芯片领域是绝对霸主！
```

### 2️⃣ 产品演进

| 产品 | 发布年 | 工艺 | HBM | 算力(FP8) |
|------|--------|------|-----|-----------|
| V100 | 2017 | 12nm | HBM2 16GB | 125 TFLOPS |
| A100 | 2020 | 7nm | HBM2e 80GB | 312 TFLOPS |
| **H100** | 2022 | 4nm | HBM3 80GB | 1979 TFLOPS |
| **H200** | 2023 | 4nm | HBM3e 141GB | 1979 TFLOPS |
| **B100** | 2024 | 4nm | HBM3e 192GB | 更高 |
| **B200** | 2025 | 3nm | HBM3e | 更高 |

### 3️⃣ 英伟达的护城河

| 护城河 | 说明 |
|--------|------|
| **CUDA生态** | 90%+的AI框架基于CUDA |
| **软件栈** | cuDNN、TensorRT等完善 |
| **先发优势** | 积累了10年+ |
| **客户绑定** | 迁移成本极高 |
| **硬件领先** | 性能持续领先 |

---

## 三、主要AI芯片玩家

### 国际巨头

| 公司 | 产品 | 定位 | 客户 | 市占率 |
|------|------|------|------|--------|
| **英伟达** | H100/H200/B100 | 训练+推理霸主 | 全球云厂商 | 85%+ |
| **AMD** | MI300X/MI325 | 追赶者 | 微软、Meta | 8% |
| **Intel** | Gaudi 3 | 追赶者 | 部分云厂商 | 2% |
| **谷歌** | TPU v5 | 自用ASIC | 谷歌云 | 4% |
| **亚马逊** | Trainium 2 | 自用ASIC | AWS | 1% |

### 中国AI芯片

| 公司 | 产品 | 对标 | 差距 | 现状 |
|------|------|------|------|------|
| **华为** | 昇腾910B/C | H100 | **最小** | 国内最强 |
| **寒武纪** | 思元590 | A100 | 1-2代 | **上市公司** |
| **海光** | DCU | AMD MI | 2代 | 出货增长 |
| 摩尔线程 | MTT S4000 | 消费级 | 定位不同 | 游戏+AI |
| 壁仞科技 | BR100 | H100 | - | 受制裁 |

### 华为昇腾详解

```
华为AI芯片布局：

┌─────────────────────────────────────────────────────────────┐
│                    华为昇腾体系                              │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  【芯片】          【系统】           【软件】               │
│  昇腾910B/C       Atlas 800/900      MindSpore             │
│  (AI处理器)       (AI服务器)         (AI框架)              │
│                                                             │
│  优势：                                                      │
│  • 国产自主可控                                              │
│  • 有自己的软件生态（MindSpore）                             │
│  • 与华为云深度绑定                                          │
│                                                             │
│  劣势：                                                      │
│  • 性能与H100有差距                                          │
│  • 生态不如CUDA成熟                                          │
│  • 产能受设备限制                                            │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

---

## 四、国产替代

### 国产化率

| 领域 | 国产化率 | 龙头 | 差距 |
|------|----------|------|------|
| 云端训练 | <5% | 华为昇腾、寒武纪 | **差距最大** |
| 云端推理 | ~10% | 华为、寒武纪、海光 | 较大 |
| 边缘推理 | ~20% | 寒武纪、地平线 | 中等 |
| 端侧AI | ~30% | 多家 | 较小 |

### 国产AI芯片的挑战

```
1. 硬件差距
   • 性能与英伟达差1-2代
   • 制程受制裁影响

2. 软件生态
   • CUDA生态难以撼动
   • 用户迁移成本高

3. 产能限制
   • 先进制程产能有限
   • 设备受制裁
```

---

## 五、AI服务器

### 1️⃣ 是什么？

> **AI服务器 = 装着AI芯片的"超级电脑"**
>
> 把GPU/AI芯片装进服务器里，提供AI算力。

### 2️⃣ 市场规模

```
AI服务器市场规模（2025年）：

市场规模：约 500亿美元
年增速：约 30-40%
```

### 3️⃣ AI服务器 vs 普通服务器

| 对比项 | 普通服务器 | AI服务器 |
|--------|------------|----------|
| 核心部件 | CPU | **GPU/AI芯片** |
| 功耗 | ~500W | **3000W~10000W+** |
| 价格 | 几万~几十万 | **几十万~几百万** |
| 散热 | 风冷为主 | **液冷为主** |
| 互连 | 普通网络 | **NVLink/IB** |

### 4️⃣ 竞争格局

| 公司 | 国家 | 市场地位 | 主要客户 |
|------|------|----------|----------|
| **浪潮信息** | 中国 | **国内龙头** | 互联网、运营商 |
| **工业富联** | 中国 | 英伟达供应链 | 全球云厂商 |
| **新华三** | 中国 | 第二梯队 | 政企、运营商 |
| **超聚变** | 中国 | 原华为x86 | 政企 |

### 5️⃣ A股标的

| 公司 | 代码 | 主营 | 市场地位 | 核心看点 |
|------|------|------|----------|----------|
| **浪潮信息** | 000977 | AI服务器 | **国内服务器龙头** | 国内最大 |
| **工业富联** | 601138 | AI服务器 | 英伟达供应链 | 全球出货 |

---

## 六、AI散热

### 1️⃣ 是什么？

> **AI散热 = 给AI服务器"降温"**
>
> AI芯片功耗极高，必须用液冷才能带走热量。

### 2️⃣ 市场规模

```
数据中心液冷市场规模（2025年）：

市场规模：约 30亿美元
年增速：约 40-50%（快速增长）

驱动因素：
• AI服务器功耗高达10kW+
• 传统风冷无法满足
• 液冷渗透率快速提升
```

### 3️⃣ 竞争格局

| 公司 | 国家 | 市场地位 | 产品 |
|------|------|----------|------|
| **英维克** | 中国 | **温控龙头** | 液冷系统 |
| **高澜股份** | 中国 | 液冷龙头 | 冷却设备 |
| Vertiv | 美国 | 国际龙头 | 全系列 |

### 4️⃣ A股标的

| 公司 | 代码 | 主营 | 市场地位 | 核心看点 |
|------|------|------|----------|----------|
| **英维克** | 002837 | 液冷散热 | **温控龙头** | 数据中心温控 |
| **高澜股份** | 300499 | 液冷 | 液冷龙头 | 电力电子冷却 |
| **申菱环境** | 301018 | 数据中心空调 | 精密空调 | 专用空调 |

---

## 七、AI芯片的瓶颈

### 当前瓶颈

```
AI芯片供需情况（2025年）：

需求：████████████████████████████████████████ 100%
供给：██████████████████████████ 60%

主要瓶颈：
1. CoWoS先进封装产能
2. HBM产能
3. 台积电代工产能
```

| 瓶颈 | 原因 | 解决时间 |
|------|------|----------|
| **CoWoS封装** | 台积电产能有限 | 2026年缓解 |
| **HBM存储** | SK海力士产能锁定 | 2025-2026年 |
| **先进制程** | 4nm/3nm产能紧张 | 持续紧张 |

---

## 八、投资逻辑总结

### 核心逻辑

```
1. AI算力需求爆发
   • 大模型训练需要海量算力
   • AI应用落地需要推理算力
   • 利好：英伟达供应链

2. 国产替代
   • 美国限制AI芯片出口
   • 国内被迫采购华为/寒武纪
   • 利好：寒武纪、海光

3. 产业链受益
   • AI芯片带动存储（HBM）
   • AI芯片带动封装（CoWoS）
   • AI芯片带动服务器整机
```

### 风险提示

| 风险 | 说明 |
|------|------|
| ⚠️ 估值高 | AI概念估值普遍较高 |
| ⚠️ 技术差距 | 国产与英伟达差距大 |
| ⚠️ 政策风险 | 制裁可能加剧 |
| ⚠️ 竞争加剧 | 国产芯片相互竞争 |

### A股标的汇总

| 环节 | 核心标的 |
|------|----------|
| AI芯片 | **寒武纪**、**海光信息**、景嘉微 |
| AI服务器 | **浪潮信息**、**工业富联** |
| AI散热 | **英维克**、高澜股份 |

---

[上一篇：存储芯片](./07_存储芯片.md) | [返回目录](./README.md) | [下一篇：PCB与基板](./09_PCB与基板.md)
